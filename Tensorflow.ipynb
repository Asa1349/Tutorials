{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Allgemeine Infos und Grundlagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.14.0\n"
     ]
    }
   ],
   "source": [
    "# Tensorflow nach der Installation importieren und Version überprüfen\n",
    "import tensorflow as tf \n",
    "print(tf.__version__)\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Achsen / Dimensionen](https://miro.medium.com/v2/resize:fit:640/format:webp/1*T3Brxoh34F5L9fUxze0K5g.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Aufbau und die Generierung von Modellen laufen bei Keras nach dem folgendem Prinzip ab:\n",
    "* Laden von Daten\n",
    "* Definition des Modells mit keras.layers\n",
    "* Vorbereitung für das Training mit model.compile()\n",
    "* Modell trainieren mit model.fit()\n",
    "* Modell evaluieren mit model.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zusätzlicher nützlicher Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# im Falle von nerviger Protokollanzeige\n",
    "# mit TFF_CPP_MIN_LOG_LEVEL kann die Menge der Protokollausgaben von TensorFlow, die auf der C++-Ebene erzeugt werden, gesteuert werden\n",
    "# der Wert '2' gibt an, dass nur Fehlermeldungen angezeigt werden sollen\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']=2\n",
    "\n",
    "# ruft eine Liste der verfügbaren GPUs ab\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "# aktiviert das dynamische Wachstum des GPU-Speichers\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialisierung von Tensoren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grafik: Grundlegende Darstellung der Achsen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(4, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Erstellen eines 1D Tensors\n",
    "x = tf.constant(4)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1 2 3]\n",
      " [4 5 6]], shape=(2, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Erstellen eines 2D Tensors\n",
    "x = tf.constant([[1,2,3], [4,5,6]])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[4.]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Bei der Erstellung des Tensors werden bereits shape und Datentyp angegeben \n",
    "# --> 2D Tensor als Gleitkommazahl\n",
    "x = tf.constant(4, shape=(1,1), dtype=tf.float32)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 1 1], shape=(3,), dtype=int32) \n",
      "\n",
      "tf.Tensor([0 0], shape=(2,), dtype=int32) \n",
      "\n",
      "tf.Tensor(\n",
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]], shape=(3, 3), dtype=float32) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = tf.ones(3,3)\n",
    "y = tf.zeros(2,3)\n",
    "z = tf.eye(3)\n",
    "print(x, '\\n')\n",
    "print(y, '\\n')\n",
    "print(z, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-0.25618824 -2.0683844   0.0726684 ]\n",
      " [-0.25428015  1.2770005   1.1926554 ]\n",
      " [-0.86744565 -0.93437    -1.0531281 ]], shape=(3, 3), dtype=float32) \n",
      "\n",
      "tf.Tensor([[-0.8148029   0.27122068  0.43896222]], shape=(1, 3), dtype=float32) \n",
      "\n",
      "tf.Tensor([0 1 2 3 4 5 6 7 8], shape=(9,), dtype=int32) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = tf.random.normal((3,3), mean=0, stddev=1)\n",
    "y = tf.random.uniform((1,3), minval=-1, maxval=1)\n",
    "z = tf.range(9)\n",
    "print(x, '\\n')\n",
    "print(y, '\\n')\n",
    "print(z, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1. 3. 5. 7. 9.], shape=(5,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Datentyp eines Tensors ändern\n",
    "x = tf.range(start=1, limit=10, delta=2)\n",
    "x = tf.cast(x, dtype=tf.float32)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mathematische Operationen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 2 3], shape=(3,), dtype=int32)\n",
      "tf.Tensor([9 8 7], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([1,2,3])\n",
    "y = tf.constant([9,8,7])\n",
    "\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([10 10 10], shape=(3,), dtype=int32)\n",
      "tf.Tensor([10 10 10], shape=(3,), dtype=int32)\n",
      "\n",
      "tf.Tensor([-8 -6 -4], shape=(3,), dtype=int32)\n",
      "tf.Tensor([-8 -6 -4], shape=(3,), dtype=int32)\n",
      "\n",
      "tf.Tensor([ 9 16 21], shape=(3,), dtype=int32)\n",
      "tf.Tensor([ 9 16 21], shape=(3,), dtype=int32)\n",
      "\n",
      "tf.Tensor([0.11111111 0.25       0.42857143], shape=(3,), dtype=float64)\n",
      "tf.Tensor([0.11111111 0.25       0.42857143], shape=(3,), dtype=float64)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Addition\n",
    "z = tf.add(x,y)\n",
    "print(z)\n",
    "z = x + y\n",
    "print(z)\n",
    "print()\n",
    "\n",
    "# Subtraktion \n",
    "z = tf.subtract(x,y)\n",
    "print(z)\n",
    "z = x - y\n",
    "print(z)\n",
    "print()\n",
    "\n",
    "# Multiplikation \n",
    "z = tf.multiply(x,y)\n",
    "print(z)\n",
    "z = x * y\n",
    "print(z)\n",
    "print()\n",
    "\n",
    "# Division \n",
    "z = tf.divide(x,y)\n",
    "print(z)\n",
    "z = x / y\n",
    "print(z)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(46, shape=(), dtype=int32)\n",
      "tf.Tensor(46, shape=(), dtype=int32)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# dot-product\n",
    "# Tensordot führt ein Punktprodukt (elementweise Multiplikation, gefolgt von Addition) entlang der durch den Achsenparameter definierten Achsen durch\n",
    "z = tf.tensordot(x,y, axes=1)\n",
    "print(z)\n",
    "z = tf.reduce_sum(x*y, axis=0)\n",
    "print(z)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-1.2232184   0.00343027 -1.5028036 ]\n",
      " [ 2.4965363   0.3136101  -0.32030284]], shape=(2, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.8048734   0.08965924 -0.9190173   1.3195467 ]\n",
      " [ 0.48136947 -1.2613939  -1.0283977   2.51552   ]\n",
      " [-1.010696    0.36193788 -0.1555632   0.10241306]], shape=(3, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Erstellung Matrix\n",
    "x = tf.random.normal((2,3))\n",
    "y = tf.random.normal((3,4))\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 2.505065   -0.6579213   1.3544123  -1.7593716 ]\n",
      " [-1.5347044  -0.28767806 -2.5670488   4.050386  ]], shape=(2, 4), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 2.505065   -0.6579213   1.3544123  -1.7593716 ]\n",
      " [-1.5347044  -0.28767806 -2.5670488   4.050386  ]], shape=(2, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#Matrixmultiplikation\n",
    "z = tf.matmul(x,y)\n",
    "print(z)\n",
    "z = x @ y\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing von Tensoren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 2 3 4 5 6 7 8 9], shape=(9,), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor([2 3 4 5 6 7 8 9], shape=(8,), dtype=int32)\n",
      "tf.Tensor([2 3], shape=(2,), dtype=int32)\n",
      "tf.Tensor([1 2 3 4 5], shape=(5,), dtype=int32)\n",
      "tf.Tensor([1 3 5 7 9], shape=(5,), dtype=int32)\n",
      "tf.Tensor([9 8 7 6 5 4 3 2 1], shape=(9,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Vector \n",
    "x = tf.constant([1,2,3,4,5,6,7,8,9])\n",
    "# Ausgabe aller Werte\n",
    "print( x[:])\n",
    "# Ausgabe des ersten Wertes (Index 0)\n",
    "print(x[0])\n",
    "# Ausgabe der Werte von Index 1 bis Ende\n",
    "print(x[1:])\n",
    "# Ausgabe der Werte von Index 1 bis exclusive 3\n",
    "print(x[1:3])\n",
    "# Ausgabe der Werte vor Index 5\n",
    "print(x[:5])\n",
    "# überspringt jedes zweite Element\n",
    "print(x[::2])\n",
    "# Ausgabe in umgekehrter Richtung\n",
    "print(x[::-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 2], shape=(2,), dtype=int32)\n",
      "tf.Tensor([1 2], shape=(2,), dtype=int32)\n",
      "\n",
      "tf.Tensor(\n",
      "[[1 2]\n",
      " [3 4]], shape=(2, 2), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[1 2]\n",
      " [3 4]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Matrix \n",
    "x = tf.constant([[1,2],\n",
    "                [3,4],\n",
    "                [5,6]])\n",
    "print(x[0]) # gleich zu\n",
    "print(x[0,:])\n",
    "print()\n",
    "print(x[0:2]) # gleich zu\n",
    "print(x[0:2,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([4 7], shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Extrahieren bestimmter Indexen (Vector)\n",
    "x = tf.constant([1,2,3,4,5,6,7,8,9])\n",
    "\n",
    "indicies = tf.constant([3,6])\n",
    "x_ind = tf.gather(x, indicies)\n",
    "print(x_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1 2]\n",
      " [5 6]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Extrahieren bestimmter Indexen (Matrix)\n",
    "x = tf.constant([[1,2],\n",
    "                [3,4],\n",
    "                [5,6]])\n",
    "\n",
    "indicies = tf.constant([0,2])\n",
    "x_ind = tf.gather(x, indicies)\n",
    "print(x_ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 1 2 3 4 5 6 7 8], shape=(9,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.range(9)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0 1 2]\n",
      " [3 4 5]\n",
      " [6 7 8]], shape=(3, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# wandelt den Vector in eine 2D Matrix 3x3 um\n",
    "x = tf.reshape(x,(3,3))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0 3 6]\n",
      " [1 4 7]\n",
      " [2 5 8]], shape=(3, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# vertauscht die Achsen (Zeile und Spalte)\n",
    "x = tf.transpose(x, perm=[1,0])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ein Basic Neural Network bezieht sich im Allgemeinen auf ein einfaches, feedforward neuronales Netzwerk ohne spezielle Strukturen oder Schichten, die für spezifische Aufgaben optimiert sind. Ein solches Netzwerk könnte als Grundlage oder Ausgangspunkt für tiefere neuronale Netzwerke dienen, die speziell für bestimmte Anwendungen entwickelt sind.\n",
    "\n",
    "Ein einfaches, grundlegendes neuronales Netzwerk besteht aus drei Arten von Schichten:\n",
    "\n",
    "* Eingangsschicht (Input Layer): \n",
    "Diese Schicht besteht aus Neuronen, die die Merkmale oder Attribute der Eingabedaten repräsentieren. Jedes Neuron entspricht einem Merkmal.\n",
    "\n",
    "* Verdeckte Schichten (Hidden Layers): \n",
    "Diese Schichten, auch als verdeckte Schichten bezeichnet, enthalten Neuronen, die Gewichtungen und Aktivierungsfunktionen verwenden, um komplexe nichtlineare Abbildungen der Eingabedaten zu erstellen. Die Anzahl der verdeckten Schichten und die Anzahl der Neuronen in jeder Schicht können variieren.\n",
    "\n",
    "* Ausgangsschicht (Output Layer): \n",
    "Die Ausgangsschicht gibt die Vorhersagen des Modells aus. Die Anzahl der Neuronen in dieser Schicht hängt von der Art der Aufgabe ab (z.B. binäre Klassifikation, Mehrklassenklassifikation, Regression).\n",
    "\n",
    "Ein einfaches neuronales Netzwerk verwendet eine sogenannte \"feedforward\"-Struktur, was bedeutet, dass die Informationen nur in eine Richtung durch das Netzwerk fließen - von der Eingangsschicht über die verdeckten Schichten zur Ausgangsschicht. Es gibt keine Rückkopplungsschleifen, wie sie in rekurrenten neuronalen Netzwerken (RNNs) vorkommen.\n",
    "\n",
    "Diese Grundstruktur kann durch Hinzufügen von mehr verdeckten Schichten, Neuronen, Anpassen der Aktivierungsfunktionen und Implementieren von speziellen Techniken (wie Regularisierung oder Dropout) komplexere Modelle erstellen. Im Laufe der Zeit wurden verschiedene Arten von neuronalen Netzwerken entwickelt, um unterschiedliche Anwendungen zu unterstützen, darunter Convolutional Neural Networks (CNNs) für die Bildverarbeitung und Rekurrente Neuronale Netzwerke (RNNs) für die Verarbeitung von Sequenzdaten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### verwendete Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vorbereitung der Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "(60000,)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "# Datensatz laden und in Trainings- und Testdaten separieren\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "# Daten in 2D Array umwandeln und Struktur abflachen\n",
    "# '-1' bedeuted, dass die Dimension so angepasst wird, dass die Gesamtzahl der Elemente unverändert bleibt\n",
    "# Dimension 2 und 3 werden zu einer Dimension verflacht (28*28)\n",
    "# Das Ganze wird durch 255 (max. Grauwert) geteilt, um mit Zahlen zwischen o und 1 zu arbeiten (Normalisierung)\n",
    "X_train = X_train.reshape(-1, 28*28).astype('float32') / 255.0\n",
    "X_test = X_test.reshape(-1, 28*28).astype('float32') / 255.0\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequentielle API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sehr bequem, aber nicht sehr flexibel (ein Input, ein Output)\n",
    "\n",
    "Bei diesem Verfahren werden die Schichten dem Modell sequenziell hinzugefügt.\n",
    "Die Reihenfolge, in der die Schichten hinzugefügt werden, gibt die Struktur des Modells vor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"seqential_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " layer1 (Dense)              (None, 512)               401920    \n",
      "                                                                 \n",
      " layer2 (Dense)              (None, 256)               131328    \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 535818 (2.04 MB)\n",
      "Trainable params: 535818 (2.04 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Definieren eines sequentiellen Models mit 2 Schichten\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        #definiert die Eingangsschicht des neuronalen Netzwerks\n",
    "        keras.Input(shape=(28*28)),\n",
    "        layers.Dense(512, activation='relu', name='layer1'),\n",
    "        layers.Dense(256, activation='relu', name='layer2'),\n",
    "        layers.Dense(10, name='output')\n",
    "    ],\n",
    "    name='seqential_model'\n",
    ")\n",
    "\n",
    "# Modell kann auch wie folgt erstellt werden:\n",
    "# model = keras.Sequential()\n",
    "# model.add(layers.Dense(512, activation='relu'))\n",
    "# model.add(layers.Dense(256, activation='relu'))\n",
    "# model.add(layers.Dense(10))\n",
    "\n",
    "# kann bei komplexeren Modellen auch zum debuggen verwendet werden\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erklärung Dense \n",
    "\n",
    "Dense = \"vollständig verbundene Schicht\" = \"fully connected layer\"\n",
    "\n",
    "Die Dense-Schicht ist eine grundlegende und häufig verwendete Art von Schicht in neuronalen Netzwerken. \n",
    "In dieser Schicht sind alle Neuronen bzw. Knoten der vorherigen Schicht mit jedem Neuronen der aktuellen Schicht verbunden. \n",
    "Jedes Neuron in einer Dense-Schicht empfängt Eingaben von allen Neuronen der vorherigen Schicht und gibt Ausgaben an alle Neuronen der nächsten Schicht weiter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erklärung Logits\n",
    "\n",
    "Um die Logits in Wahrscheinlichkeiten umzuwandeln, wird oft die Softmax-Funktion verwendet. \n",
    "Die Softmax-Funktion normalisiert die Logits, indem sie sie in Wahrscheinlichkeiten umwandelt, sodass sie zwischen 0 und 1 liegen und sich zu 1 summiert. \n",
    "Dies ermöglicht die Interpretation der Ausgabe als Wahrscheinlichkeiten, wobei jede Zahl die Wahrscheinlichkeit darstellt, dass die Eingabe zu einer bestimmten Klasse gehört."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vorbereitung für das Training\n",
    "model.compile(\n",
    "    # Verlustfunktion\n",
    "    # Sparse Categorical Crossentropy-Verlustfunktion wird verwendet, um Klassifizierungsprobleme mit nicht-einem-hot-kodierten (sparse) Zielvariablen zu behandeln, \n",
    "    # insbesondere wenn die Vorhersagen als Logits vorliegen (bevor sie in Wahrscheinlichkeiten umgewandelt werden)\n",
    "    # from_logits=True spart die Softmax Aktivierungsfunktion in der letzten Schicht\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    # Optimierer\n",
    "    # Der Optimierer steuert, wie die Modellparameter (Gewichte) anhand des Verlustes und der Gradienten aktualisiert werden.\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    # Metriken\n",
    "    # definiert die Metriken, die während des Trainings und der Auswertung des Modells überwacht werden sollen\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welche Verlustfunktion (oder auch Kostenfunktion) is zu verwenden?\n",
    "\n",
    "categorical_crossentropy oder SparseCategoricalCrossentropy\n",
    "* Für Multiklassen-Klassifizierungsprobleme \n",
    "* z.B. Was ist auf dem Bild zu sehen?\n",
    "* SparseCC wird verwendet, wenn die Zielvariablen als Ganzzahlen vorliegen und nicht One-Hot-kodiert\n",
    "\n",
    "binary_crossentropy\n",
    "* für binäre Klassifizizierungsprobleme\n",
    "* z.B. Hund oder Katze?\n",
    "\n",
    "MeanSquaredError / MSE\n",
    "* für Regressionsprobleme\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1429/1429 - 6s - loss: 0.1884 - accuracy: 0.9430 - 6s/epoch - 4ms/step\n",
      "Epoch 2/5\n",
      "1429/1429 - 6s - loss: 0.0773 - accuracy: 0.9759 - 6s/epoch - 4ms/step\n",
      "Epoch 3/5\n",
      "1429/1429 - 6s - loss: 0.0526 - accuracy: 0.9828 - 6s/epoch - 4ms/step\n",
      "Epoch 4/5\n",
      "1429/1429 - 6s - loss: 0.0386 - accuracy: 0.9878 - 6s/epoch - 4ms/step\n",
      "Epoch 5/5\n",
      "1429/1429 - 6s - loss: 0.0311 - accuracy: 0.9896 - 6s/epoch - 4ms/step\n",
      "239/239 - 0s - loss: 0.0715 - accuracy: 0.9813 - 418ms/epoch - 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07151065766811371, 0.9812999963760376]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model trainieren\n",
    "# batch_size legt die Anzahl der Beispiele fest, die gleichzeitig durch das Netzwerk propagiert werden, bevor ein Gradientenabstiegsschritt erfolgt.\n",
    "# epochs gibt an, wie oft das Modell über den gesamten Satz an Trainingsdaten trainiert werden soll.\n",
    "#verbose steuert den Anzeigemodus während des Trainings für eine Detailansicht der Fortschrittsanzeige (wie z.B. Verlust und Genauigkeit) für jede Epoche.\n",
    "model.fit(X_train, y_train, batch_size=42, epochs=5, verbose=2)\n",
    "\n",
    "# Model evaluieren\n",
    "# evaluate wird verwendet, um die Leistung des trainierten Modells anhand von Testdaten zu bewerten. \n",
    "model.evaluate(X_test, y_test, batch_size=42, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Modell kann mit verschiedenen Methoden evaluiert werden. \n",
    "\n",
    "Methode 1 - validation_split\n",
    "* model.fit(X_train, y_train, batch_size=42, epochs=5, validation_split=0.3)\n",
    "* hier wird der Trainingsdatensatz in 70% Trainings- und 30% Validierungsdaten geteilt\n",
    "* Der Nachteil von validation_split ist, dass die Daten nicht durchgemischt werden. Das kann z.B. mit einem aufruf von np.random.shuffle() gemacht werden\n",
    "\n",
    "\n",
    "Methode 2 - validation_data\n",
    "* model.fit(X_train, y_train, batch_size=42, epochs=5, validation_data=(input_validation_data, output_validation_data))\n",
    "* die Validierungsdaten werden vorher manuell angelegt\n",
    "\n",
    "Methode 3 - evaluate()\n",
    "* model.evaluate(X_test, y_test)\n",
    "* die Evaluation wird nach dem Training ausgeführt und sollte mit Daten erfolgen, die das Modell noch nicht kennt\n",
    "* dabei werden die Loss- und Accuracy-Metriken ausgegeben"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funktionale API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "etwas mehr flexibel (multiple Inputs, multiple Outputs)\n",
    "\n",
    "Mit dieser Form der Modellerstellung können Modelle mit mehreren Eingängen und mehreren Ausgängen, sogenannte azyklische Graphen, geschaffen werden, was beim Sequential-Modell nicht möglich ist. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inputs (InputLayer)         [(None, 784)]             0         \n",
      "                                                                 \n",
      " layer1 (Dense)              (None, 512)               401920    \n",
      "                                                                 \n",
      " layer2 (Dense)              (None, 256)               131328    \n",
      "                                                                 \n",
      " outputs (Dense)             (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 535818 (2.04 MB)\n",
      "Trainable params: 535818 (2.04 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Definition eines funktionalen Models mit 2 Schichten\n",
    "inputs = keras.Input(shape=(28*28), name='inputs')\n",
    "layer1 = layers.Dense(512, activation='relu', name='layer1')(inputs)\n",
    "layer2 = layers.Dense(256, activation='relu', name='layer2')(layer1)\n",
    "outputs = layers.Dense(10, activation='softmax', name='outputs')(layer2)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs, name=\"functional_model\")\n",
    "\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1429/1429 - 6s - loss: 0.0130 - accuracy: 0.9961 - 6s/epoch - 4ms/step\n",
      "Epoch 2/5\n",
      "1429/1429 - 6s - loss: 0.0090 - accuracy: 0.9973 - 6s/epoch - 4ms/step\n",
      "Epoch 3/5\n",
      "1429/1429 - 5s - loss: 0.0058 - accuracy: 0.9983 - 5s/epoch - 4ms/step\n",
      "Epoch 4/5\n",
      "1429/1429 - 5s - loss: 0.0037 - accuracy: 0.9988 - 5s/epoch - 4ms/step\n",
      "Epoch 5/5\n",
      "1429/1429 - 5s - loss: 0.0026 - accuracy: 0.9993 - 5s/epoch - 4ms/step\n",
      "239/239 - 0s - loss: 0.0999 - accuracy: 0.9843 - 409ms/epoch - 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0999363511800766, 0.9843000173568726]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vorbereitung für das Training\n",
    "model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False), # hier kann 'False' verwendet werden, da die Softmax Aktivierungsfunktion in der output Schicht definiert ist\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Model trainieren\n",
    "model.fit(X_train, y_train, batch_size=42, epochs=5, verbose=2)\n",
    "\n",
    "# Model evaluieren\n",
    "model.evaluate(X_test, y_test, batch_size=42, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extrahieren von Layer Features für Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 2s 1ms/step\n",
      "(60000, 256)\n",
      "1875/1875 [==============================] - 2s 1ms/step\n",
      "(60000, 256)\n",
      "1875/1875 [==============================] - 3s 1ms/step\n",
      "(60000, 784)\n",
      "(60000, 512)\n",
      "(60000, 256)\n"
     ]
    }
   ],
   "source": [
    "# Ausgabe eines Layers per Index\n",
    "model = keras.Model(inputs=model.inputs, \n",
    "                    outputs=[model.layers[-2].output])\n",
    "\n",
    "feature = model.predict(X_train)\n",
    "print(feature.shape)\n",
    "\n",
    "# Asugabe eines Layers per Layername\n",
    "model = keras.Model(inputs=model.inputs, \n",
    "                    outputs=[model.get_layer('layer2').output])\n",
    "\n",
    "feature = model.predict(X_train)\n",
    "print(feature.shape)\n",
    "\n",
    "model = keras.Model(inputs=model.inputs, \n",
    "                    outputs=[layer.output for layer in model.layers])\n",
    "\n",
    "features = model.predict(X_train)\n",
    "for feature in features:\n",
    "    print(feature.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network - CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ein Convolutional Neural Network (CNN oder ConvNet) ist eine spezielle Art von künstlichem neuronalen Netzwerk, das besonders gut für die Verarbeitung von strukturierten Gitterdaten geeignet ist, wie sie in Bildern und Videos vorkommen. CNNs haben in der Bildverarbeitung, Mustererkennung und anderen Aufgaben, bei denen räumliche Strukturen wichtig sind, große Erfolge erzielt.\n",
    "\n",
    "Hier sind einige der wichtigsten Eigenschaften von Convolutional Neural Networks:\n",
    "\n",
    "* Convolutional Layers (Faltungsschichten): \n",
    "CNNs verwenden spezielle Schichten, die als Convolutional Layers bezeichnet werden. Diese Schichten führen Faltungsoperationen auf den Eingabedaten aus, um lokale Muster und Merkmale zu erkennen.\n",
    "\n",
    "* Pooling Layers (Pooling-Schichten): \n",
    "Nach den Convolutional Layers folgen oft Pooling Layers, die dazu dienen, die räumliche Dimension der Daten zu reduzieren. Max-Pooling ist eine häufige Pooling-Methode, bei der der maximalste Wert in einem bestimmten Bereich ausgewählt wird.\n",
    "\n",
    "* Aktivierungsfunktionen: \n",
    "Wie in traditionellen neuronalen Netzwerken verwenden CNNs Aktivierungsfunktionen wie ReLU (Rectified Linear Unit), um Nichtlinearitäten einzuführen und die Expressivität des Modells zu erhöhen.\n",
    "\n",
    "* Fully Connected Layers (Vollständig verbundene Schichten): \n",
    "Nach den Convolutional- und Pooling-Layers können Fully Connected Layers (Dense Layers) hinzugefügt werden, um die extrahierten Merkmale in eine Ausgabe umzuwandeln, die für die spezifische Aufgabe des Modells relevant ist.\n",
    "\n",
    "* Gewichtete Verbindungen und Filter: \n",
    "In CNNs werden Gewichtungen (Filter) gemeinsam genutzt, um lokale Muster zu erkennen, was die Anzahl der lernbaren Parameter im Vergleich zu vollständig verbundenen Netzwerken reduziert.\n",
    "\n",
    "CNNs sind besonders effektiv bei der Verarbeitung von Bildern, da sie die räumlichen Hierarchien und Merkmale von Bildern auf natürliche Weise erfassen können. Sie werden in zahlreichen Anwendungen eingesetzt, darunter Bilderkennung, Gesichtserkennung, Objekterkennung, Segmentierung und mehr."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### verwendete Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers, regularizers\n",
    "from keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vorbereitung der Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(10000, 32, 32, 3)\n",
      "(50000, 1)\n",
      "(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Datensatz laden und in Trainings- und Testdaten separieren\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "# Daten normalisieren\n",
    "# beim Convolutional Model vorerst kein Flattening\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition und Training des Modells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definition eines einfachen sequentiellen Modells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"conv_seqential_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 30, 30, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 15, 15, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 13, 13, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 6, 6, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 4, 4, 128)         73856     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                131136    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 225034 (879.04 KB)\n",
      "Trainable params: 225034 (879.04 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Definition eines sequentiellen Modells \n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        # definiert die Eingangsschicht des neuronalen Netzwerks mit einer Bildgröße von 32x32 Pixeln und 3 Farbkanälen (RGB)\n",
    "        keras.Input(shape=(32,32,3)),\n",
    "        # Fügt eine Convolutional-Schicht mit 32 Filtern, einer Filtergröße von 3x3, der Aktivierungsfunktion 'relu' und der Padding-Methode 'valid' hinzu\n",
    "        layers.Conv2D(32, 3, padding='valid',activation='relu'),\n",
    "        # Fügt eine Max-Pooling-Schicht mit einer Pooling-Größe von 2x2 hinzu\n",
    "        layers.MaxPooling2D(pool_size=(2,2)),\n",
    "        # weitere Convolutional-Schicht mit 64 Filtern\n",
    "        layers.Conv2D(64, 3, activation='relu'),\n",
    "        # Standard-Pooling-Größe von 2x2\n",
    "        layers.MaxPooling2D(),\n",
    "        # weitere Convolutional-Schicht mit 128 Filtern\n",
    "        layers.Conv2D(128, 3, activation='relu'),\n",
    "        # Flacht die Ausgabe der vorherigen Schicht zu einem eindimensionalen Vektor für die Fully-Connected-Schichten\n",
    "        layers.Flatten(),\n",
    "        # Dense-Schicht mit 64 Neuronen\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        # 10 Neuronen für die Ausgabe zur Klassifizierung in 10 Klassen\n",
    "        layers.Dense(10)\n",
    "    ],\n",
    "    name='conv_seqential_model'\n",
    ")\n",
    "\n",
    "# kann bei komplexeren Modellen auch zum debuggen verwendet werden {mit abgeänderter Layer generierung}\n",
    "# model = keras.Sequential()\n",
    "# {model.add(layers.Dense(512, activation='relu'))}\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erklärung der Schichten und Parameter\n",
    "\n",
    "Conv2D-Schichten: \n",
    "\n",
    "* Diese Schichten führen Faltungen auf den Eingangsbildern durch, um Merkmale zu extrahieren. \n",
    "Die Schichten verwenden verschiedene Filter (32, 64 und 128), die jeweils mit einer Größe von 3x3 auf die Eingangsbilder angewendet werden. \n",
    "Die Aktivierungsfunktion 'relu' wird verwendet, um Nichtlinearität hinzuzufügen.\n",
    "\n",
    "\n",
    "MaxPooling2D-Schichten: \n",
    "\n",
    "* Diese Schichten reduzieren die Dimensionalität der Daten, indem sie die maximalen Werte aus kleineren Fenstern extrahieren. \n",
    "Hier werden zwei Max-Pooling-Schichten mit verschiedenen Pooling-Größen verwendet.\n",
    "\n",
    "\n",
    "padding\n",
    "\n",
    "* ist eine Einstellung, die angibt, wie mit den Bildrändern umgegangen wird, wenn eine Faltung auf das Eingangsbild angewendet wird.\n",
    "\n",
    "\n",
    "padding='valid'\n",
    "\n",
    "* Wenn padding='valid' verwendet wird, bedeutet das, dass keine zusätzliche Füllung (Padding) am Rand des Bildes hinzugefügt wird, bevor die Faltung angewendet wird. \n",
    "Mit diesem Setting führt die Faltung dazu, dass die Ausgabegröße kleiner ist als die Eingabegröße. \n",
    "Wenn das Filterkernel (Faltungskern) über den Rand des Bildes hinausragt, werden nur die Bereiche des Bildes verwendet, die komplett vom Filter abgedeckt werden können.\n",
    "\n",
    "\n",
    "padding='same'\n",
    "\n",
    "* Wenn padding='same' verwendet wird, bedeutet das, dass die Eingabe mit zusätzlichen Nullen (Padding) an den Rändern versehen wird, um sicherzustellen, dass die Ausgabegröße der Faltung dieselbe ist wie die Eingabegröße.\n",
    "Mit dieser Einstellung wird sichergestellt, dass die Filteroperationen auch auf die Pixel am Rand des Bildes angewendet werden können, \n",
    "indem zusätzliche Pixel hinzugefügt werden, um die Randbedingungen zu erfüllen. \n",
    "Das Padding wird so berechnet, dass die Ausgabegröße der Faltung dieselben Dimensionen hat wie die Eingabegröße."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 - 16s - loss: 1.6838 - accuracy: 0.3850 - 16s/epoch - 21ms/step\n",
      "Epoch 2/10\n",
      "782/782 - 16s - loss: 1.3528 - accuracy: 0.5163 - 16s/epoch - 20ms/step\n",
      "Epoch 3/10\n",
      "782/782 - 16s - loss: 1.2190 - accuracy: 0.5712 - 16s/epoch - 21ms/step\n",
      "Epoch 4/10\n",
      "782/782 - 16s - loss: 1.1274 - accuracy: 0.6049 - 16s/epoch - 20ms/step\n",
      "Epoch 5/10\n",
      "782/782 - 16s - loss: 1.0516 - accuracy: 0.6342 - 16s/epoch - 20ms/step\n",
      "Epoch 6/10\n",
      "782/782 - 15s - loss: 0.9878 - accuracy: 0.6558 - 15s/epoch - 20ms/step\n",
      "Epoch 7/10\n",
      "782/782 - 16s - loss: 0.9370 - accuracy: 0.6738 - 16s/epoch - 20ms/step\n",
      "Epoch 8/10\n",
      "782/782 - 16s - loss: 0.8903 - accuracy: 0.6883 - 16s/epoch - 20ms/step\n",
      "Epoch 9/10\n",
      "782/782 - 16s - loss: 0.8504 - accuracy: 0.7049 - 16s/epoch - 20ms/step\n",
      "Epoch 10/10\n",
      "782/782 - 16s - loss: 0.8145 - accuracy: 0.7207 - 16s/epoch - 20ms/step\n",
      "157/157 - 1s - loss: 0.8873 - accuracy: 0.6942 - 993ms/epoch - 6ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8873369097709656, 0.6941999793052673]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vorbereitung für das Training\n",
    "model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Trainieren des Models\n",
    "model.fit(X_train, y_train, batch_size=64, epochs=10, verbose=2)\n",
    "# Evaluieren des Models\n",
    "model.evaluate(X_test, y_test, batch_size=64, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definition eines Models mit BatchNormalization und Regularisierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " batch_normalization_15 (Ba  (None, 32, 32, 32)        128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " tf.nn.relu_15 (TFOpLambda)  (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPooli  (None, 16, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_16 (Ba  (None, 16, 16, 64)        256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " tf.nn.relu_16 (TFOpLambda)  (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPooli  (None, 8, 8, 64)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 8, 8, 128)         73856     \n",
      "                                                                 \n",
      " batch_normalization_17 (Ba  (None, 8, 8, 128)         512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " tf.nn.relu_17 (TFOpLambda)  (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 8192)              0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 64)                524352    \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 619146 (2.36 MB)\n",
      "Trainable params: 618698 (2.36 MB)\n",
      "Non-trainable params: 448 (1.75 KB)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def my_model():\n",
    "    inputs = keras.Input(shape=(32,32,3))\n",
    "    x = layers.Conv2D(32, 3, padding='same', kernel_regularizer=regularizers.L2(0.01))(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = keras.activations.relu(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    x = layers.Conv2D(64, 3, padding='same', kernel_regularizer=regularizers.L2(0.01))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = keras.activations.relu(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    x = layers.Conv2D(128, 3, padding='same', kernel_regularizer=regularizers.L2(0.01))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = keras.activations.relu(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(64, activation='relu', kernel_regularizer=regularizers.L2(0.01))(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(10)(x)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = my_model()\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Die Batch-Normalisierung (Batch Normalization, kurz BN) ist eine Technik, die zur Verbesserung der Konvergenz und Stabilität des Trainings beiträgt, insbesondere bei tiefen neuronalen Netzwerken. \n",
    " Hier sind die Hauptfunktionen der Batch-Normalization:\n",
    "\n",
    "1. Normalisierung:\n",
    "\n",
    "* Die Batch-Normalization normalisiert die Aktivierungen einer Schicht, indem der Mittelwert der Aktivierungen subtrahiert und das Ergebnis durch die Standardabweichung geteilt wird.\n",
    "* Dies hilft, die Aktivierungen auf eine ähnliche Skala zu bringen und das Training zu beschleunigen.\n",
    "\n",
    "\n",
    "2. Skalierung und Verschiebung:\n",
    "\n",
    "* Zusätzlich zur Normalisierung fügt die Batch-Normalization zwei lernbare Parameter hinzu: einen für die Skalierung und einen für die Verschiebung.\n",
    "* Diese Parameter ermöglichen es dem Modell, die normalisierten Aktivierungen zu skalieren und zu verschieben, um die Flexibilität des Modells beizubehalten.\n",
    "\n",
    "\n",
    "3. Regularisierungseffekt:\n",
    "\n",
    "* Batch-Normalization wirkt als eine Art Regularisierung, da der Mini-Batch-Mittelwert und die Standardabweichung während des Trainings verwendet werden.\n",
    "* Dies kann helfen, Overfitting zu reduzieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 - 41s - loss: 3.0448 - accuracy: 0.3448 - 41s/epoch - 53ms/step\n",
      "Epoch 2/10\n",
      "782/782 - 38s - loss: 1.9550 - accuracy: 0.4506 - 38s/epoch - 49ms/step\n",
      "Epoch 3/10\n",
      "782/782 - 37s - loss: 1.6590 - accuracy: 0.5014 - 37s/epoch - 47ms/step\n",
      "Epoch 4/10\n",
      "782/782 - 37s - loss: 1.5239 - accuracy: 0.5323 - 37s/epoch - 48ms/step\n",
      "Epoch 5/10\n",
      "782/782 - 39s - loss: 1.4539 - accuracy: 0.5517 - 39s/epoch - 49ms/step\n",
      "Epoch 6/10\n",
      "782/782 - 39s - loss: 1.4095 - accuracy: 0.5603 - 39s/epoch - 50ms/step\n",
      "Epoch 7/10\n",
      "782/782 - 39s - loss: 1.3791 - accuracy: 0.5730 - 39s/epoch - 50ms/step\n",
      "Epoch 8/10\n",
      "782/782 - 39s - loss: 1.3531 - accuracy: 0.5797 - 39s/epoch - 49ms/step\n",
      "Epoch 9/10\n",
      "782/782 - 39s - loss: 1.3302 - accuracy: 0.5901 - 39s/epoch - 50ms/step\n",
      "Epoch 10/10\n",
      "782/782 - 40s - loss: 1.3125 - accuracy: 0.5946 - 40s/epoch - 51ms/step\n",
      "157/157 - 2s - loss: 1.2359 - accuracy: 0.6335 - 2s/epoch - 13ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.2359070777893066, 0.6334999799728394]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vorbereitung für das Training\n",
    "model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Trainieren des Models\n",
    "model.fit(X_train, y_train, batch_size=64, epochs=10, verbose=2)\n",
    "# Evaluieren des Models\n",
    "model.evaluate(X_test, y_test, batch_size=64, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Neural Network - RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ein Recurrent Neural Network (RNN) ist ein Typ künstlicher neuronaler Netzwerke, der für die Verarbeitung von sequenziellen Daten entwickelt wurde. Im Gegensatz zu traditionellen neuronalen Netzwerken, die keine spezifische Struktur für die Verarbeitung von Sequenzen haben, sind RNNs darauf ausgelegt, zeitabhängige Informationen in den Daten zu erfassen.\n",
    "\n",
    "Hier sind einige Schlüsselmerkmale von Rekurrenten Neuralen Netzwerken:\n",
    "\n",
    "* Rekurrente Schichten (Recurrent Layers): \n",
    "Die Hauptkomponente eines RNNs ist die rekurrente Schicht. Diese Schicht ermöglicht es dem Netzwerk, Informationen aus vorherigen Zeitschritten zu speichern und in den aktuellen Schritt zu übertragen. Dadurch können RNNs zeitabhängige Muster in den Daten modellieren.\n",
    "\n",
    "* Gewichtete Rückkopplung (Weighted Feedback): \n",
    "Rekurrente Schichten verwenden gewichtete Rückkopplung, um Informationen aus vorherigen Zeitschritten zu berücksichtigen. Dies ermöglicht dem Netzwerk, sich an vorherige Zustände zu \"erinnern\" und diese Informationen bei Bedarf zu verwenden.\n",
    "\n",
    "* Aktivierungsfunktionen: \n",
    "Wie in anderen neuronalen Netzwerken auch verwenden RNNs Aktivierungsfunktionen wie Tanh oder ReLU, um Nichtlinearitäten einzuführen und die Ausdrucksfähigkeit des Modells zu erhöhen.\n",
    "\n",
    "* Zeitreihendaten: \n",
    "RNNs sind besonders geeignet für die Verarbeitung von Zeitreihendaten, bei denen die Reihenfolge der Daten von Bedeutung ist, wie z. B. in Sprachverarbeitung, maschinellem Übersetzen, Textgenerierung und Aktienpreisvorhersagen.\n",
    "\n",
    "Obwohl RNNs dazu neigen, gut mit Sequenzdaten umzugehen, haben sie Schwierigkeiten, lange Abhängigkeiten zu erfassen, was als das \"Vanishing Gradient Problem\" bekannt ist. Um dieses Problem zu überwinden, wurden fortgeschrittenere Varianten von RNNs entwickelt, darunter Long Short-Term Memory Networks (LSTM) und Gated Recurrent Units (GRU), die speziell darauf abzielen, langfristige Abhängigkeiten zu erfassen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### verwendete Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vorbereitung der Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "(60000,)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "# Datensatz laden und in Trainings- und Testdaten separieren\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Daten normalisieren\n",
    "# beim Recurrent Model vorerst kein Flattening\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition und Training des Modells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definition eines einfachen RNN Modells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"RNN_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_4 (SimpleRNN)    (None, None, 256)         72960     \n",
      "                                                                 \n",
      " simple_rnn_5 (SimpleRNN)    (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 206858 (808.04 KB)\n",
      "Trainable params: 206858 (808.04 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(name='RNN_model')\n",
    "#Der None-Wert in der ersten Dimension bedeutet, dass das Netzwerk mit Sequenzen unterschiedlicher Länge umgehen kann (typisch für RNNs).\n",
    "model.add(keras.Input(shape=(None, 28)))\n",
    "model.add(layers.SimpleRNN(256, return_sequences=True, activation='tanh'))\n",
    "model.add(layers.SimpleRNN(256, activation='tanh'))\n",
    "model.add(layers.Dense(10))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rekurrente Schicht (layers.SimpleRNN):\n",
    "\n",
    "* Die erste rekurrente Schicht hat 256 Einheiten (Neuronen) und verwendet die Tangens hyperbolicus (tanh)-Aktivierungsfunktion.\n",
    "* return_sequences=True bedeutet, dass die Schicht eine Sequenz von Ausgaben für jeden Zeitschritt zurückgibt, anstatt nur die letzte Ausgabe der Sequenz.\n",
    "* Diese Einstellung ist typisch, wenn Sie mehrere aufeinander folgende rekurrente Schichten haben, da Sie normalerweise die Sequenzinformationen für die nächste Schicht beibehalten möchten.\n",
    "* Die zweite rekurrente Schicht hat ebenfalls 256 Einheiten und verwendet tanh als Aktivierungsfunktion.\n",
    "* Im Gegensatz zur ersten Schicht hat diese return_sequences standardmäßig auf False, was bedeutet, dass nur die letzte Ausgabe der Sequenz zurückgegeben wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 - 19s - loss: 0.6176 - accuracy: 0.7918 - 19s/epoch - 20ms/step\n",
      "Epoch 2/10\n",
      "938/938 - 18s - loss: 0.3265 - accuracy: 0.9005 - 18s/epoch - 19ms/step\n",
      "Epoch 3/10\n",
      "938/938 - 18s - loss: 0.3136 - accuracy: 0.9057 - 18s/epoch - 19ms/step\n",
      "Epoch 4/10\n",
      "938/938 - 20s - loss: 0.2662 - accuracy: 0.9206 - 20s/epoch - 21ms/step\n",
      "Epoch 5/10\n",
      "938/938 - 20s - loss: 0.2232 - accuracy: 0.9362 - 20s/epoch - 22ms/step\n",
      "Epoch 6/10\n",
      "938/938 - 21s - loss: 0.2100 - accuracy: 0.9392 - 21s/epoch - 22ms/step\n",
      "Epoch 7/10\n",
      "938/938 - 20s - loss: 0.2284 - accuracy: 0.9328 - 20s/epoch - 21ms/step\n",
      "Epoch 8/10\n",
      "938/938 - 20s - loss: 0.1998 - accuracy: 0.9412 - 20s/epoch - 21ms/step\n",
      "Epoch 9/10\n",
      "938/938 - 20s - loss: 0.2230 - accuracy: 0.9349 - 20s/epoch - 21ms/step\n",
      "Epoch 10/10\n",
      "938/938 - 20s - loss: 0.2019 - accuracy: 0.9415 - 20s/epoch - 21ms/step\n",
      "157/157 - 1s - loss: 0.1997 - accuracy: 0.9413 - 1s/epoch - 9ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1996881365776062, 0.9412999749183655]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=64, epochs=10, verbose=2)\n",
    "model.evaluate(X_test, y_test, batch_size=64, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definition eines einfachen RNN Modells mit GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"GRU_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_1 (GRU)                 (None, None, 256)         219648    \n",
      "                                                                 \n",
      " gru_2 (GRU)                 (None, 256)               394752    \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 616970 (2.35 MB)\n",
      "Trainable params: 616970 (2.35 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(name='GRU_model')\n",
    "model.add(keras.Input(shape=(None, 28)))\n",
    "model.add(layers.GRU(256, return_sequences=True, activation='tanh'))\n",
    "model.add(layers.GRU(256, activation='tanh'))\n",
    "model.add(layers.Dense(10))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dieser Code basiert auf auf Gated Recurrent Units (GRUs).\n",
    "GRUs sind eine spezielle Form von rekurrenten neuronalen Netzwerken, die dazu entwickelt wurden, das Problem des \"Vanishing Gradient\" bei langen Abhängigkeiten zu mildern, ähnlich wie Long Short-Term Memory Networks (LSTM).\n",
    "\n",
    "Schlüsselmerkmale von GRUs sind:\n",
    "\n",
    "Gating-Mechanismus: <br>\n",
    "GRUs verwenden einen Gating-Mechanismus, um zu steuern, welche Informationen in den verdeckten Zustand übernommen werden und welche verworfen werden sollen. Dieser Mechanismus besteht aus zwei Toren: <br>\n",
    "dem \"Reset Gate\" und dem \"Update Gate\". <br>\n",
    "Das \"Reset Gate\" entscheidet, welche Informationen aus dem vorherigen Zustand verworfen werden sollen. <br>\n",
    "Das \"Update Gate\" entscheidet, welche neuen Informationen in den Zustand aufgenommen werden sollen.\n",
    "\n",
    "Verdeckter Zustand (Hidden State): <br>\n",
    "    Ähnlich wie bei LSTM hat auch GRU einen verdeckten Zustand, der Informationen über mehrere Zeitschritte hinweg speichert. Der Gating-Mechanismus steuert, wie dieser Zustand aktualisiert wird.\n",
    "\n",
    "Einfachere Struktur: <br>\n",
    "    Im Vergleich zu LSTM ist die Struktur von GRU simpler. Es gibt nur einen Zustand, und die Gating-Mechanismen sind weniger komplex. Dies kann zu einer einfachen Implementierung und schnelleren Trainingszeiten führen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "938/938 - 80s - loss: 0.2365 - accuracy: 0.9233 - 80s/epoch - 86ms/step\n",
      "Epoch 2/10\n",
      "938/938 - 80s - loss: 0.0756 - accuracy: 0.9766 - 80s/epoch - 85ms/step\n",
      "Epoch 3/10\n",
      "938/938 - 83s - loss: 0.0574 - accuracy: 0.9825 - 83s/epoch - 89ms/step\n",
      "Epoch 4/10\n",
      "938/938 - 84s - loss: 0.0464 - accuracy: 0.9851 - 84s/epoch - 89ms/step\n",
      "Epoch 5/10\n",
      "938/938 - 82s - loss: 0.0408 - accuracy: 0.9869 - 82s/epoch - 87ms/step\n",
      "Epoch 6/10\n",
      "938/938 - 82s - loss: 0.0374 - accuracy: 0.9880 - 82s/epoch - 88ms/step\n",
      "Epoch 7/10\n",
      "938/938 - 83s - loss: 0.0344 - accuracy: 0.9886 - 83s/epoch - 89ms/step\n",
      "Epoch 8/10\n",
      "938/938 - 83s - loss: 0.0331 - accuracy: 0.9891 - 83s/epoch - 89ms/step\n",
      "Epoch 9/10\n",
      "938/938 - 83s - loss: 0.0305 - accuracy: 0.9902 - 83s/epoch - 89ms/step\n",
      "Epoch 10/10\n",
      "938/938 - 84s - loss: 0.0301 - accuracy: 0.9902 - 84s/epoch - 89ms/step\n",
      "157/157 - 4s - loss: 0.0496 - accuracy: 0.9854 - 4s/epoch - 23ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.04961291328072548, 0.9854000210762024]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=64, epochs=10, verbose=2)\n",
    "model.evaluate(X_test, y_test, batch_size=64, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definition eines bidirektionalen RNN Modells mit LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(name='bidirectional_model')\n",
    "model.add(keras.Input(shape=(None, 28)))\n",
    "model.add(layers.Bidirectional(layers.LSTM(256, return_sequences=True, activation='tanh')))\n",
    "model.add(layers.GRU(256, activation='tanh'))\n",
    "model.add(layers.Dense(10))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dieser Code verwendet eine bidirektionale Schicht, um sowohl vorwärts als auch rückwärts durch eine LSTM-Schicht zu gehen und Informationen von beiden Richtungen zu erfassen.\n",
    "\n",
    "LSTM steht für \"Long Short-Term Memory\" und dient ebenso zur Überwindung des \"Vanishing Gradient\" Problems.\n",
    "\n",
    "Schlüsselmerkmale des LSTM sind:\n",
    "\n",
    "Langzeitabhängigkeiten: <br>\n",
    "LSTMs sind darauf ausgerichtet, lange Abhängigkeiten zwischen den Zeitschritten in einer Sequenz zu erfassen. Dies ermöglicht es ihnen, Informationen über einen längeren Zeitraum zu speichern und zu verwenden, was besonders wichtig ist, wenn die Sequenzen, die sie verarbeiten, lang sind.\n",
    "\n",
    "Zelle (Cell): <br>\n",
    "Die grundlegende Einheit eines LSTM-Netzwerks ist die LSTM-Zelle. Diese Zelle hat interne Zustände, die aktualisiert und modifiziert werden können. Die Zellzustände ermöglichen es dem LSTM, Informationen über mehrere Zeitschritte hinweg zu speichern.\n",
    "\n",
    "Eingangstore (Input Gate), Vergessenstore (Forget Gate) und Ausgangstore (Output Gate): <br>\n",
    "LSTMs verwenden spezielle Tore, um zu steuern, welche Informationen in den Zellzustand eingegeben, vergessen oder aus diesem ausgegeben werden sollen. Jedes Tor ist mit einer Sigmoid-Aktivierungsfunktion versehen, die Werte zwischen 0 und 1 ausgibt und somit den Grad der Informationseingabe oder -ausgabe steuert.\n",
    "\n",
    "Aktivierungsfunktionen: <br> \n",
    "In einer LSTM-Zelle werden normalerweise die Tangens hyperbolicus (tanh)-Aktivierungsfunktion und die Sigmoid-Aktivierungsfunktionen verwendet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speichern und Laden von Modellen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speichern als h5-Datei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speichern des Models\n",
    "model.save('Model_name.h5')\n",
    "\n",
    "# Laden des Models\n",
    "model = keras.load_model('Model_name.h5')\n",
    "\n",
    "# Model verwenden und Vorhersage treffen\n",
    "result = model.predict([5,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speichern als SavedModel-Format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beim SavedModel-Format wird die Modelldefinition in das angegebene Unterverzeichnis exportiert. \n",
    "\n",
    "Das SavedModel-Format ermöglicht die Benutzung des Modells in TensorFlow Lite, TensorFlow Serving, TensorFlow Hub oder sogar in TensorFlow.js, nachdem es konvertiert wurde.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speichern des Models\n",
    "tf.saved_model.save(model, 'Model_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Struktur und Parameter seperat speichern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Struktur eines Modells kann seperat von den Parametern gespeichert werden, wenn man z.B. die Modellstruktur visualisieren will. Dabei sind Gewichtungen udn Bias wenig nützlich und deshalb bietet Keras eine Möglichkeit zur seperaten Speicherung von Struktur und Parameter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gewichte speichern (h5-Datei)\n",
    "model.save_weights('Model_name')\n",
    "\n",
    "\n",
    "# Struktur des Modells als JSON speichern\n",
    "json_str = model.to_json()\n",
    "\n",
    "with open('Model_name.json', 'w') as json_file:\n",
    "    json_file.write(json_str)\n",
    "\n",
    "\n",
    "# Modell mit struktur und Parameter laden\n",
    "with open('Model_name.json', 'r') as f:\n",
    "    json_file_content = f.read()\n",
    "\n",
    "model = keras.model_from_json(json_file_content)\n",
    "model.load_weights('Model_name.h5')\n",
    "\n",
    "\n",
    "# Für YAML einfach json durch yaml ersetzen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras-Modelle für TensorFlow.js exportieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vorraussetzung: pip install tensorflowjs\n",
    "import tensorflowjs as tfjs\n",
    "\n",
    "tfjs.converters.save_keras_model(model, './Model_name')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
